{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpJ7s_SIVu_I"
   },
   "source": [
    "# Trabajo Práctico Final: Linear/Quadratic Discriminant Analysis (LDA/QDA)\n",
    "\n",
    "### Definición: Clasificador Bayesiano\n",
    "\n",
    "Sean $k$ poblaciones, $x \\in \\mathbb{R}^p$ puede pertenecer a cualquiera $g \\in \\mathcal{G}$ de ellas. Bajo un esquema bayesiano, se define entonces $\\pi_j \\doteq P(G = j)$ la probabilidad *a priori* de que $X$ pertenezca a la clase *j*, y se **asume conocida** la distribución condicional de cada observable dado su clase $f_j \\doteq f_{X|G=j}$.\n",
    "\n",
    "De esta manera dicha probabilidad *a posteriori* resulta\n",
    "$$\n",
    "P(G|_{X=x} = j) = \\frac{f_{X|G=j}(x) \\cdot p_G(j)}{f_X(x)} \\propto f_j(x) \\cdot \\pi_j\n",
    "$$\n",
    "\n",
    "La regla de decisión de Bayes es entonces\n",
    "$$\n",
    "H(x) \\doteq \\arg \\max_{g \\in \\mathcal{G}} \\{ P(G|_{X=x} = j) \\} = \\arg \\max_{g \\in \\mathcal{G}} \\{ f_j(x) \\cdot \\pi_j \\}\n",
    "$$\n",
    "\n",
    "es decir, se predice a $x$ como perteneciente a la población $j$ cuya probabilidad a posteriori es máxima.\n",
    "\n",
    "*Ojo, a no desesperar! $\\pi_j$ no es otra cosa que una constante prefijada, y $f_j$ es, en su esencia, un campo escalar de $x$ a simplemente evaluar.*\n",
    "\n",
    "### Distribución condicional\n",
    "\n",
    "Para los clasificadores de discriminante cuadrático y lineal (QDA/LDA) se asume que $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma_j)$, es decir, se asume que cada población sigue una distribución normal.\n",
    "\n",
    "Por definición, se tiene entonces que para una clase $j$:\n",
    "$$\n",
    "f_j(x) = \\frac{1}{(2 \\pi)^\\frac{p}{2} \\cdot |\\Sigma_j|^\\frac{1}{2}} e^{- \\frac{1}{2}(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)}\n",
    "$$\n",
    "\n",
    "Aplicando logaritmo (que al ser una función estrictamente creciente no afecta el cálculo de máximos/mínimos), queda algo mucho más práctico de trabajar:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Observar que en este caso $C=-\\frac{p}{2} \\log(2\\pi)$, pero no se tiene en cuenta ya que al tener una constante aditiva en todas las clases, no afecta al cálculo del máximo.\n",
    "\n",
    "### LDA\n",
    "\n",
    "En el caso de LDA se hace una suposición extra, que es $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma)$, es decir que las poblaciones no sólo siguen una distribución normal sino que son de igual matriz de covarianzas. Reemplazando arriba se obtiene entonces:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva y, distribuyendo y reagrupando términos sobre $(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$ se obtiene finalmente:\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
    "$$\n",
    "\n",
    "\n",
    "### Entrenamiento/Ajuste\n",
    "\n",
    "Obsérvese que para ambos modelos, ajustarlos a los datos implica estimar los parámetros $(\\mu_j, \\Sigma_j) \\; \\forall j = 1, \\dots, k$ en el caso de QDA, y $(\\mu_j, \\Sigma)$ para LDA.\n",
    "\n",
    "Estos parámetros se estiman por máxima verosimilitud, de manera que los estimadores resultan:\n",
    "\n",
    "* $\\hat{\\mu}_j = \\bar{x}_j$ el promedio de los $x$ de la clase *j*\n",
    "* $\\hat{\\Sigma}_j = s^2_j$ la matriz de covarianzas estimada para cada clase *j*\n",
    "* $\\hat{\\pi}_j = f_{R_j} = \\frac{n_j}{n}$ la frecuencia relativa de la clase *j* en la muestra\n",
    "* $\\hat{\\Sigma} = \\frac{1}{n} \\sum_{j=1}^k n_j \\cdot s^2_j$ el promedio ponderado (por frecs. relativas) de las matrices de covarianzas de todas las clases. *Observar que se utiliza el estimador de MV y no el insesgado*\n",
    "\n",
    "Es importante notar que si bien todos los $\\mu, \\Sigma$ deben ser estimados, la distribución *a priori* puede no inferirse de los datos sino asumirse previamente, utilizándose como entrada del modelo.\n",
    "\n",
    "### Predicción\n",
    "\n",
    "Para estos modelos, al igual que para cualquier clasificador Bayesiano del tipo antes visto, la estimación de la clase es por método *plug-in* sobre la regla de decisión $H(x)$, es decir devolver la clase que maximiza $\\hat{f}_j(x) \\cdot \\hat{\\pi}_j$, o lo que es lo mismo $\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TDWOgpJWKQa"
   },
   "source": [
    "## Estructura del código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yEV8WbiWl6k"
   },
   "source": [
    "## Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "teF9O9JJmG7Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import det, inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sDBLvbTtlwzs"
   },
   "outputs": [],
   "source": [
    "class ClassEncoder:\n",
    "  def fit(self, y):\n",
    "    self.names = np.unique(y)\n",
    "    self.name_to_class = {name:idx for idx, name in enumerate(self.names)}\n",
    "    self.fmt = y.dtype\n",
    "    \n",
    "    # Q1: why is there no need for class_to_name?\n",
    "    # Porque con el diccionario creado se puede acceder por la clave o el valor\n",
    "    #  Ej. \n",
    "    #     print(list(self.name_to_class.values())[0])\n",
    "    #     print(list(self.name_to_class.keys())[0])\n",
    "\n",
    "  def _map_reshape(self, f, arr):\n",
    "\n",
    "    return np.array([f(elem) for elem in arr.flatten()]).reshape(arr.shape)\n",
    "\n",
    "    # Q2: why is reshaping necessary?\n",
    "    # Para poder recorrer todos los elementos de arr se convierte a la matriz en un vector fila mediante arr.flatten. \n",
    "    # Para poder reestablecer el formato se usa reshape  \n",
    "\n",
    "  def transform(self, y):\n",
    "    return self._map_reshape(lambda name: self.name_to_class[name], y)\n",
    "\n",
    "  def fit_transform(self, y):\n",
    "    self.fit(y)\n",
    "    return self.transform(y)\n",
    "\n",
    "  def detransform(self, y_hat):\n",
    "    return self._map_reshape(lambda idx: self.names[idx], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m0KYC8_uSOu4"
   },
   "outputs": [],
   "source": [
    "class BaseBayesianClassifier:\n",
    "  def __init__(self):\n",
    "    self.encoder = ClassEncoder()\n",
    "\n",
    "  def _estimate_a_priori(self, y):\n",
    "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
    "    \n",
    "    # Q3: what does bincount do?\n",
    "    # Cuenta la aparición de cada elemento de cada clase.\n",
    "    # En este caso cuenta cuantas veces aparece cada elemento 'y' del dataset.\n",
    "    # Por ej. cuantas 'setosa','virginica', etc. hay.\n",
    "\n",
    "    return np.log(a_priori)\n",
    "    \n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate all needed parameters for given model\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def fit(self, X, y, a_priori=None):\n",
    "    # first encode the classes\n",
    "\n",
    "    y = self.encoder.fit_transform(y)\n",
    "    \n",
    "    # if it's needed, estimate a priori probabilities\n",
    "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
    "\n",
    "    # check that a_priori has the correct number of classes\n",
    "    assert len(self.log_a_priori) == len(self.encoder.names), \"A priori probabilities do not match number of classes\"\n",
    "\n",
    "    # now that everything else is in place, estimate all needed parameters for given model\n",
    "    self._fit_params(X, y)\n",
    "    \n",
    "    # Q4: why do we need to do this last, can't we do it first?\n",
    "    # No se puede hacer inmediatamente despues de \"def fit\" porque _fit_params necesita tener resuelto self.log_a_priori \n",
    "\n",
    "  def predict(self, X):\n",
    "    # this is actually an individual prediction encased in a for-loop\n",
    "    m_obs = X.shape[1]\n",
    "\n",
    "    y_hat = np.empty(m_obs, dtype=self.encoder.fmt)\n",
    "    \n",
    "    for i in range(m_obs):\n",
    "      encoded_y_hat_i = self._predict_one(X[:,i].reshape(-1,1))\n",
    "      y_hat[i] = self.encoder.names[encoded_y_hat_i]\n",
    "           \n",
    "    # return prediction as a row vector (matching y)\n",
    "    return y_hat.reshape(1,-1)\n",
    "\n",
    "  def _predict_one(self, x):\n",
    "    # calculate all log posteriori probabilities (actually, +C)\n",
    "    log_posteriori = [log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i \n",
    "                  in enumerate(self.log_a_priori) ]\n",
    "    \n",
    "    # return the class that has maximum a posteriori probability\n",
    "    return np.argmax(log_posteriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IRamFdiGDuSR"
   },
   "outputs": [],
   "source": [
    "class QDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate each covariance matrix\n",
    "    \n",
    "    self.inv_covs = [inv(np.cov(X[:, y.flatten()==idx], bias=True)) \n",
    "                      for idx in range(len(self.log_a_priori))]\n",
    "    \n",
    "    # Q5: why not just X[:,y==idx]?\n",
    "    # 'y' es una matriz pero se requiere un vector para usar como indice de columnas de X\n",
    "    \n",
    "    # Q6: what does bias=True mean? why not use bias=False?\n",
    "    # np.cov estima la matriz de covarianza. \n",
    "    # Con bias=True la normalización se hace con todos los valores de N. Si bias=False la normalización es por (N - 1) , \n",
    "    # donde N es el número de observaciones dadas (estimación insesgada). \n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True) \n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "    \n",
    "    # Q7: what does axis=1 mean? why not axis=0 instead?\n",
    "    # axis=1 significa que el arreglo se recorre por columnas. axis=0 es por filas. Cada columna de X tienen la \n",
    "    # descripcion de los atributos de una flor por eso hay que recorrer columna por columna.\n",
    "    \n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    inv_cov = self.inv_covs[class_idx]\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "    return 0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUEVO CÓDIGO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QDA1(QDA):\n",
    "\n",
    "  def _estimate_a_priori(self, y):\n",
    "    a_priori = np.ones([len(self.encoder.names)], dtype = int) * 1/len(self.encoder.names)\n",
    "\n",
    "    return np.log(a_priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    # estimate each covariance matrix\n",
    "                      \n",
    "    #self.inv_covs = [inv(np.cov(X[:, y.flatten()==0], bias=True)) \n",
    "    #                  for idx in range(len(self.log_a_priori))]\n",
    "    \n",
    "    #inv_cov_mean = np.mean([np.cov(X[:, y.flatten()==idx], bias=True)\n",
    "    #                  for idx in range(len(self.log_a_priori))])\n",
    "    \n",
    "    #self.inv_cov = inv(inv_cov_mean)\n",
    "      \n",
    "    #a = np.array([[1, 2], [2, 4]])\n",
    "    # np.mean([a for i in range(3)], axis=0)\n",
    "    \n",
    "    self.inv_cov = inv(np.cov(X[:, y.flatten()==0], bias=True)) \n",
    "    \n",
    "    # print('self.inv_covs : \\n',self.inv_cov)\n",
    "\n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True) \n",
    "                  for idx in range(len(self.log_a_priori))]\n",
    "    \n",
    "    # print('self.means : \\n', self.means)\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    inv_cov = self.inv_cov\n",
    "    unbiased_x =  x - 0.5 * self.means[class_idx]\n",
    "    \n",
    "    # retorna el log de la prediccion de acuerdo a la formula para LDA\n",
    "    return self.means[class_idx].T @ inv_cov @ unbiased_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS_zoK-gWkRf"
   },
   "source": [
    "## Código para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m05KrhUDINVs"
   },
   "outputs": [],
   "source": [
    "# hiperparámetros\n",
    "#rng_seed =  6543\n",
    "#rng_seed =  1234\n",
    "#rng_seed =  2\n",
    "rng_seed =  9347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hkXcoldXOqs",
    "outputId": "b07a5027-be83-4c0a-a09e-e4f3a21e4c5f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4), Y:(150, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def get_iris_dataset():\n",
    "  data = load_iris()\n",
    "  X_full = data.data\n",
    "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
    "  return X_full, y_full\n",
    "\n",
    "X_full, y_full = get_iris_dataset()\n",
    "\n",
    "print(f\"X: {X_full.shape}, Y:{y_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAk-UQCjKecT",
    "outputId": "ddf4e2f6-1baf-4a51-de72-5ce1d7c03db8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek data matrix\n",
    "X_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdzMURX2KVdO",
    "outputId": "66a3cd6b-7dda-4618-b13f-628d113bf7d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa'],\n",
       "       ['setosa']], dtype='<U10')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek target vector\n",
    "y_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKP_QmWCIECs",
    "outputId": "36c28bcc-5d33-43e6-f231-3f3bf7b460cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 90) (1, 90) (4, 60) (1, 60)\n"
     ]
    }
   ],
   "source": [
    "# preparing data, train - test validation\n",
    "# 70-30 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.4, random_state=rng_seed)\n",
    "\n",
    "# traspose everything because this model format assumes column vectors\n",
    "train_x = X_train.T\n",
    "train_y = y_train.T\n",
    "test_x = X_test.T\n",
    "test_y = y_test.T\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dGIf2TA5SpoT"
   },
   "outputs": [],
   "source": [
    "qda = QDA()\n",
    "#qda = QDA1()\n",
    "#qda = LDA()\n",
    "\n",
    "qda.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0Q30DyLWpTL",
    "outputId": "c113c448-5230-44be-8f85-7a6d3f732d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0111 while test error is 0.0167\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "  return (y_true == y_pred).mean()\n",
    "\n",
    "train_acc = accuracy(train_y, qda.predict(train_x))\n",
    "test_acc = accuracy(test_y, qda.predict(test_x))\n",
    "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yb1V7_yXRfO"
   },
   "source": [
    "# Consigna\n",
    "\n",
    "## Implementación\n",
    "1. Entrenar un modelo QDA utilizando ahora una *a priori* uniforme ¿Se observan diferencias?¿Por qué?\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "El resultado es : Train (apparent) error is 0.0222 while test error is 0.0167\n",
    "\n",
    "Se ve que asumiendo una distribución uniforme el error en test es mayor que el mismo error tomando la frecuencia relativa. Porque el método asume una distribución uniforme. \n",
    "\n",
    "En test los resultados son iguales para ambas a_priori. \n",
    "\n",
    "2. Implementar el modelo LDA, entrenarlo y testearlo contra los mismos sets que QDA ¿Se observan diferencias? ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?\n",
    "\n",
    "LDA da : Train (apparent) error is 0.0333 while test error is 0.0167\n",
    "\n",
    "En train el error se triplicó pero en test no se aprecian diferencias.\n",
    "\n",
    "3. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Qué se observa?\n",
    "\n",
    "Los valores utilizados son : \\\n",
    "Con LDA : \\\n",
    "rng_seed =  6543 : Train (apparent) error is 0.0333 while test error is 0.0167 \\\n",
    "rng_seed =  1234 : Train (apparent) error is 0.0333 while test error is 0.0167 \\\n",
    "rng_seed =  2    : Train (apparent) error is 0.0222 while test error is 0.0667 \\\n",
    "rng_seed =  9347 : Train (apparent) error is 0.0444 while test error is 0.0333 \n",
    "\n",
    "Con QDA : \\\n",
    "rng_seed =  6543 : Train (apparent) error is 0.0111 while test error is 0.0167 \\\n",
    "rng_seed =  1234 : Train (apparent) error is 0.0222 while test error is 0.0000 \\\n",
    "rng_seed =  2    : Train (apparent) error is 0.0333 while test error is 0.0167 \\\n",
    "rng_seed =  9347 : Train (apparent) error is 0.0111 while test error is 0.0167 \n",
    "\n",
    "\n",
    "1. *(Opcional)* En `BaseBayesianClassifier._predict_one` se estima la posteriori de cada clase por separado, a pesar de que la cuenta es siempre la misma (cambiando valores de parámetros, pero no dimensiones). Aprovechando el *broadcasting* de NumPy, se puede reemplazar ese list comprehension por un cálculo *tensorizado* donde tanto medias como varianzas (o inversas) estén \"stackeadas\" sobre un tercer eje, permitiendo el cálculo en paralelo de todas las clases con un:\n",
    "`log_posteriori = self.tensor_log_a_priori + self._predict_log_conditionals(x)`. Implementar dicha modificación y mostrar su uso. *Ayuda: los métodos `np.stack` y la documentación del operador [`@`](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) son de gran utilidad.*\n",
    "\n",
    "## Preguntas técnicas\n",
    "\n",
    "Responder las 7 preguntas que se encuentran distribuidas a lo largo del código.\n",
    "\n",
    "Respuesta : Ver código\n",
    "\n",
    "## Preguntas teóricas\n",
    "\n",
    "1. En LDA se menciona que la función a maximizar puede ser, mediante operaciones, convertida en:\n",
    "$$\n",
    "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
    "$$\n",
    "Mostrar los pasos por los cuales se llega a dicha expresión.\n",
    "--------------------------------------------------------------------------------------\n",
    "Respuesta :\n",
    "\n",
    "\n",
    "$$\n",
    "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "\n",
    "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva. \n",
    "\n",
    "Partimos de la ecuación $\\log{f_j(x)} =  - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C'$\n",
    "\n",
    "$$\n",
    "- \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) = -\\frac{1}{2} (x^T \\Sigma^{-1} x - x^T \\Sigma^{-1} \\mu_j - \\mu_j^T \\Sigma^{-1} x + \\mu_j^T \\Sigma^{-1} \\mu_j) \n",
    "$$\n",
    "\n",
    "$(x^T \\Sigma^{-1} \\mu_j)$ es un número real -----> $x^T \\Sigma^{-1} \\mu_j = (x^T \\Sigma^{-1} \\mu_j)^T$, ademas $\\Sigma$ es simetrica, entonces $\\Sigma^{-1} = (\\Sigma^{-1})^T$\n",
    "\n",
    "Por lo anterior :  $x^T \\Sigma^{-1} \\mu_j = \\mu_j^T  \\Sigma^{-1}  x $\n",
    "\n",
    "$$\n",
    "- \\frac{1}{2} (x^T \\Sigma^{-1} x - x^T \\Sigma^{-1} \\mu_j - \\mu_j^T \\Sigma^{-1} x + \\mu_j^T \\Sigma^{-1} \\mu_j) = - \\frac{1}{2} (x^T \\Sigma^{-1} x - \\mu_j^T \\Sigma^{-1} x - \\mu_j^T \\Sigma^{-1} x + \\mu_j^T \\Sigma^{-1} \\mu_j) = -\\frac{1}{2} (x^T \\Sigma^{-1} x - 2 \\mu_j^T \\Sigma^{-1} x + \\mu_j^T \\Sigma^{-1} \\mu_j) \n",
    "$$\n",
    "\n",
    "$ (x^T \\Sigma^{-1} x)$ no depende de la población, por lo cual podemos quitarla de la comparación\n",
    "\n",
    "$$\n",
    "-\\frac{1}{2} (x^T \\Sigma^{-1} x - 2 \\mu_j^T \\Sigma^{-1} x + \\mu_j^T \\Sigma^{-1} \\mu_j) = \\mu_j^T \\Sigma^{-1} x -\\frac{1}{2} (\\mu_j^T \\Sigma^{-1} \\mu_j) \n",
    "$$\n",
    "$$\n",
    "= \\mu_j^T \\Sigma^{-1} (x-\\frac{1}{2} \\mu_j)\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------\n",
    "\n",
    "2. Explicar, utilizando las respectivas funciones a maximizar, por qué QDA y LDA son \"quadratic\" y \"linear\".\n",
    "\n",
    "\n",
    "Respuesta :\n",
    "Cuando la covarianza se asume igual en todas las clases se simplifica el termino cuadratico y queda una ecuación lineal:\n",
    "\n",
    "$$\n",
    "\\log{f_1(x)} - \\log{f_2(x)}=  -\\frac{1}{2} (x^T \\Sigma_1^{-1} x - 2 \\mu_1^T \\Sigma_1^{-1} x + \\mu_1^T \\Sigma_1^{-1} \\mu_1) - ( -\\frac{1}{2} (x^T \\Sigma_2^{-1} x - 2 \\mu_2^T \\Sigma_2^{-1} x + \\mu_2^T \\Sigma_2^{-1} \\mu_2))\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{1}{2} [(x^T \\Sigma_1^{-1} x - 2 \\mu_1^T \\Sigma_1^{-1} x + \\mu_1^T \\Sigma_1^{-1} \\mu_1) - (x^T \\Sigma_2^{-1} x - 2 \\mu_2^T \\Sigma_2^{-1} x + \\mu_2^T \\Sigma_2^{-1} \\mu_2)]\n",
    "$$\n",
    "\n",
    "\n",
    "Podemos separar la acuación en terminos cuadraticos ($x^{2}$), lineales (x) e independiente (no contiene x): \n",
    "$$\n",
    "= -\\frac{1}{2} x^T (\\Sigma_1^{-1} - \\Sigma_2^{-1}) x + (\\mu_1^T \\Sigma_1^{-1} - \\mu_2^T \\Sigma_2^{-1})x-\\frac{1}{2}(\\mu_1^T \\Sigma_1^{-1} \\mu_1 - \\mu_2^T \\Sigma_2^{-1} \\mu_2)\n",
    "$$\n",
    "\n",
    "Se puede apreciar que si las covarianzas son iguales en todos las clases el termino $x^T (\\Sigma_1^{-1} - \\Sigma_2^{-1}) x $ queda como $x^T (\\Sigma^{-1} - \\Sigma^{-1}) x $ y desparece de la ecuación, pasando de una ecuación cuadratica (QDA) a una ecuación lineal (LDA)\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "3. La implementación de QDA estima la probabilidad condicional utilizando `0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x` que no es *exactamente* lo descrito en el apartado teórico ¿Cuáles son las diferencias y por qué son expresiones equivalentes?\n",
    "\n",
    "Respuesta :\n",
    "\n",
    "La ecuación del apartado teorico es : $\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C$\n",
    "\n",
    "Analizando cada uno de los terminos se ve que la diferencia está en el termino '0.5*np.log(det(inv_cov))'\n",
    "\n",
    "0.5 * np.log(det(inv_cov)) = $\\frac{1}{2} \\log |\\Sigma^{-1}|$ =? $-\\frac{1}{2}\\log |\\Sigma|$\n",
    "\n",
    "Considerando que el determinante de la inversa de una matriz es igual a la inversa del determinate de la matriz se puede hacer : \n",
    "\n",
    "$\\frac{1}{2}\\log |\\Sigma^{-1}|= \\frac{1}{2}\\log (\\frac{1}{|\\Sigma|})=\\frac{1}{2}(\\log(1) - log |\\Sigma|) = \\frac{1}{2} (0 - log |\\Sigma|) = - \\frac{1}{2} log |\\Sigma|$\n",
    "\n",
    "\n",
    "-0.5 * unbiased_x.T = $- \\frac{1}{2} (x-\\mu_j)^T$\n",
    "\n",
    "inv_cov = $\\Sigma^{-1}$\n",
    "\n",
    "unbiased_x = $(x- \\mu_j)$\n",
    "\n",
    "Se comprueba que la ecuación del programa es igual a la ecuación de la teoría\n",
    "\n",
    "------------------------------------------------------------------\n",
    "\n",
    "El espíritu de esta componente práctica es la de establecer un mínimo de trabajo aceptable para su entrega; se invita al alumno a explorar otros aspectos que generen curiosidad, sin sentirse de ninguna manera limitado por la consigna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ChynN-GXSL5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AMIA - TP final LDA/QDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
